Import Packages
---------------

.. code:: ipython3

    import os
    import rdkit.Chem as Chem
    import rdkit.Chem.AllChem as AllChem
    from rdkit.Chem import PandasTools
    import rdkit.Chem.Fragments as Fragments
    from rdkit.Chem import MACCSkeys
    from rdkit import RDLogger
    RDLogger.DisableLog('rdApp.*')
    
    import random
    import numpy as np
    import matplotlib.pyplot as plt
    from sklearn.metrics import confusion_matrix
    from sklearn.metrics import RocCurveDisplay
    import torch
    import torch.nn as nn
    from torch.utils.data import TensorDataset, DataLoader
    
    import sys
    curr_dir = os.path.abspath(".")
    util_dir = os.path.join(os.path.dirname(curr_dir))
    sys.path.append(util_dir)
    from utils.fnn_models import FCNNBtachModel as Model

Curate Dataset
--------------

.. code:: ipython3

    infile = "../data/combined_training_datasets_unique.sdf"
    name = os.path.splitext(os.path.basename(infile))[0]
    
    all_df = PandasTools.LoadSDF(infile)
    all_df.head()




.. raw:: html

    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }
    
        .dataframe tbody tr th {
            vertical-align: top;
        }
    
        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>pKa</th>
          <th>marvin_pKa</th>
          <th>marvin_atom</th>
          <th>marvin_pKa_type</th>
          <th>original_dataset</th>
          <th>ID</th>
          <th>ROMol</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>6.21</td>
          <td>6.09</td>
          <td>10</td>
          <td>basic</td>
          <td>['chembl25']</td>
          <td>1702768</td>
          <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7f2d4808dc40&gt;</td>
        </tr>
        <tr>
          <th>1</th>
          <td>7.46</td>
          <td>8.2</td>
          <td>9</td>
          <td>basic</td>
          <td>['chembl25']</td>
          <td>273537</td>
          <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7f2c3c15f530&gt;</td>
        </tr>
        <tr>
          <th>2</th>
          <td>4.2</td>
          <td>3.94</td>
          <td>9</td>
          <td>basic</td>
          <td>['datawarrior']</td>
          <td>7175</td>
          <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7f2c3c15e260&gt;</td>
        </tr>
        <tr>
          <th>3</th>
          <td>3.73</td>
          <td>5.91</td>
          <td>8</td>
          <td>acidic</td>
          <td>['datawarrior']</td>
          <td>998</td>
          <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7f2c3c15eb90&gt;</td>
        </tr>
        <tr>
          <th>4</th>
          <td>11.0</td>
          <td>8.94</td>
          <td>13</td>
          <td>basic</td>
          <td>['chembl25']</td>
          <td>560562</td>
          <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7f2c3c15d8c0&gt;</td>
        </tr>
      </tbody>
    </table>
    </div>



.. code:: ipython3

    patterns = []
    for patstr in dir(Chem.Fragments):
        if patstr.startswith("fr"):
            patterns.append(patstr)
    print(f"Number of fragment patterns: {len(patterns)}")
    
    PATTERNS = [getattr(Fragments, patstr) for patstr in patterns]
    
    def featurize(mol):
        counts = [pattern(mol) for pattern in PATTERNS]
        return counts
    
    X = []
    Y = []
    
    for idx, row in all_df.iterrows():
        x = featurize(row["ROMol"])
        X.append(x)
        Y.append(row["pKa"])
    X = np.array(X, dtype=float)
    Y = np.array(Y, dtype=float)
    Y = np.where(Y<7, 1, 0).reshape(-1, 1) # binary label
    
    nsamples = X.shape[0]
    ndim = X.shape[1]


.. parsed-literal::

    Number of fragment patterns: 85


Hyperparameters
---------------

.. code:: ipython3

    # for reproduce purposes
    SEED = 0
    random.seed(SEED)
    np.random.seed(SEED)
    torch.manual_seed(SEED)
    
    datadir = "."
    ratio = 0.1
    batch_size= 256
    epochs = 50
    lr = 5e-3
    device = "cuda" if torch.cuda.is_available() else "cpu"

Split dataset
-------------

.. code:: ipython3

    def random_split(X, Y, ratio):
        nsamples = X.shape[0]
        val_size = int(nsamples*ratio)
        val_indices = np.random.choice(nsamples, val_size, replace=False)
        train_indices = set(range(nsamples)) - set(val_indices.tolist())
        train_indices = list(train_indices)
        X_train, Y_train = X[train_indices], Y[train_indices]
        X_test, Y_test = X[val_indices], Y[val_indices]
        return (X_train, Y_train), (X_test, Y_test)
    
    (X_train, Y_train), (X_test, Y_test) = random_split(X, Y, ratio)

.. code:: ipython3

    X_train = torch.from_numpy(X_train).float()
    Y_train = torch.from_numpy(Y_train).float()
    X_test = torch.from_numpy(X_test).float()
    Y_test = torch.from_numpy(Y_test).float()
    train_loader = DataLoader(TensorDataset(X_train, Y_train), batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(TensorDataset(X_test, Y_test), batch_size=batch_size, shuffle=False)

Model
-----

.. code:: ipython3

    def train_epoch(dataloader, model, loss_func, optimizer, device):
        model.train()
        train_loss = []
        for (x, y) in dataloader:
                x, y = x.to(device), y.to(device)
                optimizer.zero_grad()
                y_pred = torch.sigmoid(model(x))
                loss = loss_func(y_pred, y)
                loss.backward()
                optimizer.step()
                train_loss.append(loss.detach().cpu().numpy())
        return np.mean(train_loss)
    
    def val_epoch(dataloader, loss_func, model, device):
        model.eval()
        val_loss = []
        with torch.no_grad():
            for (x, y) in dataloader:
                x, y = x.to(device), y.to(device)
                y_pred = torch.sigmoid(model(x))
                loss = loss_func(y_pred, y)
                val_loss.append(loss.detach().cpu().numpy())
        return np.mean(val_loss)

Training
--------

.. code:: ipython3

    model = Model(ndim, hidden_dims=[100, 50, 20])
    model.to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    loss_func = nn.BCELoss() # binary cross entropy
    
    train_epoch_losses, test_epoch_losses = [], []
    for n in range(epochs):
        train_epoch_loss = train_epoch(train_loader, model, loss_func, optimizer, device)
        val_epoch_loss = val_epoch(test_loader, loss_func, model, device)
        train_epoch_losses.append(train_epoch_loss)
        test_epoch_losses.append(val_epoch_loss)

.. code:: ipython3

    plt.plot(train_epoch_losses, label="Train")
    plt.plot(test_epoch_losses, label="Test")
    plt.legend()




.. parsed-literal::

    <matplotlib.legend.Legend at 0x7f2c3c1ce950>




.. image:: output_14_1.png


Analysis
--------

.. code:: ipython3

    model.eval()
    with torch.no_grad():
        truth = Y_test.to(device)
        pred = torch.sigmoid(model(X_test.to(device)))
        l = nn.BCELoss()(pred, truth)
        print(l)


.. parsed-literal::

    tensor(0.3970)


.. code:: ipython3

    display = RocCurveDisplay.from_predictions(
        truth.cpu().numpy().reshape(-1).astype(int),
        pred.cpu().numpy().reshape(-1),
        color="darkorange",
        plot_chance_level=True,
    )
    _ = display.ax_.set(
        xlabel="False Positive Rate",
        ylabel="True Positive Rate",
        title="ROC (Acidic vs Basic)",
    )



.. image:: output_17_0.png


.. code:: ipython3

    cutoff = 0.50
    mtx = confusion_matrix(truth.cpu().numpy().reshape(-1), pred.cpu().numpy().reshape(-1)>cutoff)
    tn, fp, fn, tp = mtx.ravel()
    print(f"Accuracy: {(tn+tp)/(tn+fp+fn+tp)*100:.2f}%")
    print(f"Confusion matrix: {os.linesep} {mtx}")


.. parsed-literal::

    Accuracy: 88.98%
    Confusion matrix: 
     [[264  26]
     [ 40 269]]


